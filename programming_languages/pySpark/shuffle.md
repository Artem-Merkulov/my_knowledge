# Shuffling

Shuffle - это способ перераспределения данных между разделами, который может быть ресурсозатратным 
из-за передачи больших объемов данных по сети и использования структур данных в памяти.

 
Допустим у нас есть 3 партиции на 2-х исполнителях. В партициях вперемешку перечислены виды животных,
такие как: fish, bird, dog, cat.

Нам нужно сделать группировку и получить 4 партиции с одним и тем же видом животного:
1 партиция: только bird, 2 партиция: только fish, 3 партиция: только cat, 4 партиция: только dog.

При выполнении операции `группировка` Spark будет применять `shuffle`.

Spark применяет `shuffle` при следующих типах операций:
* groupBy() - группировка
* join() - объединение 
* repartition() - изменение числа партиций
* distinct() - выделение уникальных значений

Поэтому `shuffle` практически неизбежен для приложений spark.

`Shuffle` ресурсозатратен по следующим причинам:
* Потенциальная передача больших объёмов данных по сети
* Реорганизация записей

Spark использует структуры данных в памяти для реорганизации записи перед их передачей, что требует 
вычислительной мощности и памяти.

Посколько `shuffle` очень ресурсозатратная операция - важно сводить к минимуму количество `shuffle`,
которые происходят во время выполнения программы.

### Как определить количество shuffle

Пример с `join`:

1. Смотрим план запроса (Графическая версия). Будет написано `Exchange`, там где происходит `shuffle`.
там же можно будет увидеть количество партиций по-умолчанию, установленное Spark.
2. Меняем порядок join так, чтобы `shuffle` не происходил повторно. Так, чтобы это не влияло на логику.
(Повышение эффективности не стоит потери корректности.)

![Shuffling](https://datastrophic.io/blog/2016-03-03/dag-logical-view.png "Shuffling")